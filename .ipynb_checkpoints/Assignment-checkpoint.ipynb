{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "This is a sample RNN code.\n",
    "Using this original code, you could already get a 0.63 accuracy.\n",
    "Please make some changes instead of submitting the original code.\n",
    "If you have some questions about the code or data,\n",
    "please contact M.M. Kuang(kuangmeng@hku.hk) or Y.Q. Deng(yqdeng@cs.hku.hk)\n",
    "\"\"\"\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "map_fn = tf.map_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "def str_2_list(data_list):\n",
    "    ret_list = []\n",
    "    for i in range(len(data_list)):\n",
    "        tmp_list = data_list[i].strip().split(\" \")\n",
    "        tmp_ret_list = [int(tmp_list[7][0]),int(tmp_list[6]),int(tmp_list[5]),int(tmp_list[4]),int(tmp_list[3]),int(tmp_list[2]),int(tmp_list[1]),int(tmp_list[0][1])] #changed\n",
    "        ret_list.append(tmp_ret_list)\n",
    "    return ret_list\n",
    "\n",
    "# Prepare Data(Training and Testing)\n",
    "filename = \"data.txt\"\n",
    "a_list = []\n",
    "b_list = []\n",
    "c_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, \"r\") as file:\n",
    "    filein = file.read().splitlines()\n",
    "    for item in filein:\n",
    "        tmp_list = item.strip().split(\",\")\n",
    "        a_list.append(tmp_list[0])\n",
    "        b_list.append(tmp_list[1])\n",
    "        c_list.append(tmp_list[2])\n",
    "a_list = str_2_list(a_list)\n",
    "b_list = str_2_list(b_list)\n",
    "c_list = str_2_list(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataflow graph\n",
    "time_steps = 8        # time steps which is the same as the length of the bit-string\n",
    "input_dim = 2         # number of units in the input layer\n",
    "hidden_dim = 24      # number of units in the hidden layer\n",
    "output_dim = 1        # number of units in the output layer\n",
    "binary_dim = 8\n",
    "largest_number = pow(2, binary_dim)\n",
    "TINY          = 1e-6    # to avoid NaNs in logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-0193c4a346d8>:7: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-5-0193c4a346d8>:16: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# input inputs and target ouput Y\n",
    "inputs = tf.placeholder(tf.float32, [time_steps, None, input_dim], name='x')\n",
    "outputs = tf.placeholder(tf.float32, [time_steps, None, output_dim], name='y')\n",
    "\n",
    "# define the RNN cell: can be simple cell, LSTM or GRU\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(hidden_dim, state_is_tuple=True)\n",
    "# cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
    "\n",
    "batch_size    = tf.shape(inputs)[1]\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# Given inputs (time, batch, input_size) outputs a tuple\n",
    "#  - outputs: (time, batch, output_size)  [do not mistake with output_dim]\n",
    "#  - states:  (time, batch, hidden_size)\n",
    "rnn_outputs, rnn_states = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, time_major=True)\n",
    "\n",
    "# project output from rnn output size to output_dim. Sometimes it is worth adding\n",
    "# an extra layer here.\n",
    "final_projection = lambda x: layers.linear(x, num_outputs=output_dim, activation_fn=tf.nn.sigmoid)\n",
    "\n",
    "# apply projection to every timestep.\n",
    "predicted_outputs = map_fn(final_projection, rnn_outputs)\n",
    "\n",
    "# # minimize error, using ADAM as weight update rule\n",
    "error = -(outputs * tf.log(predicted_outputs + TINY) + (1.0 - outputs) * tf.log(1.0 - predicted_outputs + TINY))\n",
    "error = tf.reduce_sum(error)\n",
    "\n",
    "learning_rate = 0.06\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "decayed_lr = tf.train.exponential_decay(learning_rate, global_step, 100000, 0.99, staircase=True)\n",
    "# train_fn = tf.train.AdamOptimizer(decayed_lr).minimize(error, global_step=global_step)\n",
    "train_fn = tf.train.AdamOptimizer(learning_rate).minimize(error)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.abs(outputs - predicted_outputs) < 0.5, tf.float32))\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#Number of data for training and testing\n",
    "#Please remember the total number is 5000\n",
    "num4train = 3000\n",
    "num4valid = 1000\n",
    "num4test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 , train err:  2841.594970703125 valid err:  5586.0596 , valid acc:  52.549999952316284\n",
      "Epoch  2 , train err:  2750.600341796875 valid err:  5434.33 , valid acc:  58.412498235702515\n",
      "Epoch  3 , train err:  2661.794230143229 valid err:  5309.327 , valid acc:  62.4750018119812\n",
      "Epoch  4 , train err:  2561.9984130859375 valid err:  5107.8604 , valid acc:  73.67500066757202\n",
      "Epoch  5 , train err:  2512.9036458333335 valid err:  4909.079 , valid acc:  71.8375027179718\n",
      "Epoch  6 , train err:  2348.051513671875 valid err:  4284.146 , valid acc:  80.44999837875366\n",
      "Epoch  7 , train err:  2122.103963216146 valid err:  3510.8643 , valid acc:  80.96250295639038\n",
      "Epoch  8 , train err:  2015.3983561197917 valid err:  3192.5405 , valid acc:  83.38750004768372\n",
      "Epoch  9 , train err:  1771.2899373372395 valid err:  2652.5698 , valid acc:  89.20000195503235\n",
      "Epoch  10 , train err:  1515.3944702148438 valid err:  2079.4038 , valid acc:  91.92500114440918\n",
      "Epoch  11 , train err:  1217.3442891438801 valid err:  1544.8907 , valid acc:  95.85000276565552\n",
      "Epoch  12 , train err:  948.0476379394531 valid err:  1077.947 , valid acc:  97.57500290870667\n",
      "Epoch  13 , train err:  680.1126963297526 valid err:  769.82623 , valid acc:  99.04999732971191\n",
      "Epoch  14 , train err:  468.46510314941406 valid err:  447.33902 , valid acc:  98.92500042915344\n",
      "Epoch  15 , train err:  624.3330383300781 valid err:  591.4647 , valid acc:  98.01250100135803\n",
      "Epoch  16 , train err:  502.96600850423175 valid err:  437.79105 , valid acc:  99.04999732971191\n",
      "Epoch  17 , train err:  368.861333211263 valid err:  339.41595 , valid acc:  99.07500147819519\n",
      "Epoch  18 , train err:  240.1901626586914 valid err:  250.32089 , valid acc:  99.72500205039978\n",
      "Epoch  19 , train err:  171.2712542215983 valid err:  140.08713 , valid acc:  100.0\n",
      "Epoch  20 , train err:  117.75222587585449 valid err:  93.35878 , valid acc:  100.0\n",
      "Epoch  21 , train err:  112.97212346394856 valid err:  71.466866 , valid acc:  100.0\n",
      "Epoch  22 , train err:  75.25671577453613 valid err:  49.99269 , valid acc:  100.0\n",
      "Epoch  23 , train err:  58.38475704193115 valid err:  38.630554 , valid acc:  100.0\n",
      "Epoch  24 , train err:  43.51897112528483 valid err:  29.775906 , valid acc:  100.0\n",
      "Epoch  25 , train err:  35.3566370010376 valid err:  24.766941 , valid acc:  100.0\n",
      "Epoch  26 , train err:  30.619831085205078 valid err:  21.445242 , valid acc:  100.0\n",
      "Epoch  27 , train err:  26.294830799102783 valid err:  18.443 , valid acc:  100.0\n",
      "Epoch  28 , train err:  22.58467721939087 valid err:  16.303528 , valid acc:  100.0\n",
      "Epoch  29 , train err:  19.289795637130737 valid err:  14.699848 , valid acc:  100.0\n",
      "Epoch  30 , train err:  17.501277287801106 valid err:  13.376994 , valid acc:  100.0\n",
      "Epoch  31 , train err:  15.796541531880697 valid err:  12.219109 , valid acc:  100.0\n",
      "Epoch  32 , train err:  14.48453982671102 valid err:  11.196245 , valid acc:  100.0\n",
      "Epoch  33 , train err:  13.469878673553467 valid err:  10.371805 , valid acc:  100.0\n",
      "Epoch  34 , train err:  12.506462176640829 valid err:  9.626398 , valid acc:  100.0\n",
      "Epoch  35 , train err:  11.68420402208964 valid err:  8.957443 , valid acc:  100.0\n",
      "Epoch  36 , train err:  10.955796798070272 valid err:  8.382101 , valid acc:  100.0\n",
      "Epoch  37 , train err:  10.286083857218424 valid err:  7.867105 , valid acc:  100.0\n",
      "Epoch  38 , train err:  9.68957777818044 valid err:  7.4001865 , valid acc:  100.0\n",
      "Epoch  39 , train err:  9.143218199412027 valid err:  6.9842587 , valid acc:  100.0\n",
      "Epoch  40 , train err:  8.643519004185995 valid err:  6.6070776 , valid acc:  100.0\n",
      "Epoch  41 , train err:  8.187812805175781 valid err:  6.2610188 , valid acc:  100.0\n",
      "Epoch  42 , train err:  7.767380118370056 valid err:  5.945268 , valid acc:  100.0\n",
      "Epoch  43 , train err:  7.379032015800476 valid err:  5.655943 , valid acc:  100.0\n",
      "Epoch  44 , train err:  7.020479679107666 valid err:  5.3891573 , valid acc:  100.0\n",
      "Epoch  45 , train err:  6.688051700592041 valid err:  5.142649 , valid acc:  100.0\n",
      "Epoch  46 , train err:  6.378940383593242 valid err:  4.914254 , valid acc:  100.0\n",
      "Epoch  47 , train err:  6.090991020202637 valid err:  4.701644 , valid acc:  100.0\n",
      "Epoch  48 , train err:  5.822178641955058 valid err:  4.5034294 , valid acc:  100.0\n",
      "Epoch  49 , train err:  5.570983966191609 valid err:  4.318261 , valid acc:  100.0\n",
      "Epoch  50 , train err:  5.3357763687769575 valid err:  4.145119 , valid acc:  100.0\n",
      "Epoch  51 , train err:  5.115144590536754 valid err:  3.9827785 , valid acc:  100.0\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "batch_size = 500\n",
    "early_stopping_tolerance = 2\n",
    "early_stopping_counter = 0\n",
    "min_valid_error = sys.maxsize\n",
    "\n",
    "\n",
    "valid_a = np.transpose([a_list[num4train: num4train + num4valid]])\n",
    "valid_b = np.transpose([b_list[num4train: num4train + num4valid]])\n",
    "valid_y = np.transpose([c_list[num4train: num4train + num4valid]])\n",
    "valid_x = np.concatenate((valid_a,valid_b), axis=2)\n",
    "\n",
    "num_of_epochs = 0\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    num_of_epochs = num_of_epochs + 1\n",
    "    train_error = 0\n",
    "    ITERATIONS_PER_EPOCH = int(num4train/batch_size)\n",
    "    for j in range(ITERATIONS_PER_EPOCH):\n",
    "        a = np.transpose([a_list[j*batch_size : (j+1)*batch_size]])\n",
    "        b = np.transpose([b_list[j*batch_size : (j+1)*batch_size]])\n",
    "        y = np.transpose([c_list[j*batch_size : (j+1)*batch_size]])\n",
    "        x = np.concatenate((a,b), axis=2)\n",
    "\n",
    "        train_error += sess.run([error, train_fn], {\n",
    "            inputs: x,\n",
    "            outputs: y,\n",
    "        })[0]\n",
    "    train_error /= ITERATIONS_PER_EPOCH\n",
    "    valid_accuracy = sess.run(accuracy, {\n",
    "        inputs:  valid_x,\n",
    "        outputs: valid_y,\n",
    "    })\n",
    "    valid_error = sess.run(error, {\n",
    "        inputs:  valid_x,\n",
    "        outputs: valid_y,\n",
    "    })\n",
    "    print(\"Epoch \", num_of_epochs, \", train err: \", train_error, \"valid err: \", valid_error, \", valid acc: \", valid_accuracy * 100.0)\n",
    "    #early stopping\n",
    "    if valid_error < 1:\n",
    "            #early stop\n",
    "            break\n",
    "            \n",
    "#     if valid_error < min_valid_error:\n",
    "#         min_valid_error = valid_error\n",
    "#         early_stopping_counter = 0\n",
    "#     else:\n",
    "#         early_stopping_counter = early_stopping_counter + 1\n",
    "#         print(\"early_stopping_counter: \" + str(early_stopping_counter))\n",
    "#         if early_stopping_counter >= early_stopping_tolerance:\n",
    "#             #early stop\n",
    "#             break\n",
    "end_time = time.time()\n",
    "\n",
    "remain_result = []\n",
    "print(\"Training Finished\")\n",
    "print(\"Training time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_result = []\n",
    "average_error = 0\n",
    "#Test\n",
    "for i in range(num4train + num4valid + 1, num4train + num4valid + num4test):\n",
    "    a = np.transpose([[a_list[i]]])\n",
    "    b = np.transpose([[b_list[i]]])\n",
    "    y = np.transpose([[c_list[i]]])\n",
    "    x = np.concatenate((a,b), axis=2)\n",
    "    \n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(y)\n",
    "    print(x)\n",
    "\n",
    "    # get predicted value\n",
    "    [_probs, _error] = sess.run([predicted_outputs, error], {inputs: x, outputs: y})\n",
    "    probs = np.array(_probs).reshape([8])\n",
    "    prediction = np.array([1 if p >= 0.5 else 0 for p in probs]).reshape([8])\n",
    "    # Save the result\n",
    "    disired_output = y.reshape([binary_dim])\n",
    "    remain_result.append([prediction, disired_output])\n",
    "\n",
    "    # calculate error\n",
    "    y = y.reshape(binary_dim)\n",
    "    probs = probs.reshape(binary_dim)\n",
    "    error_value = np.sum(np.absolute(y - probs))\n",
    "    \n",
    "    #print the prediction, the right y and the error.\n",
    "    print(\"---------------\")\n",
    "    print(prediction)\n",
    "    print(disired_output)\n",
    "    print(error_value)\n",
    "    print(\"---------------\")\n",
    "    print()\n",
    "\n",
    "average_error = average_error/num4test\n",
    "print(average_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Get the total accuracy (Please don't change this part)\n",
    "accuracy = 0\n",
    "for i in range(len(remain_result)):\n",
    "    len_ = len(remain_result[i][0])\n",
    "    tmp_num = 0\n",
    "    for j in range(len_):\n",
    "        if remain_result[i][0][j] == remain_result[i][1][j]:\n",
    "            tmp_num += 1\n",
    "    accuracy += tmp_num / len_\n",
    "\n",
    "accuracy /= len(remain_result)\n",
    "\n",
    "print(\"Accuracy: %.4f\"%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
